{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "lesson_1.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "nfRSfecExTgi",
    "u4TESt3AxXg7"
   ],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E8KtDqFlrcm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JT3FtljAhgw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1v51-gWkPgQmtIhcGpmwuw81TGwMz7aM5'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJo6HP61Ahgy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### План курса\n",
    "\n",
    "1. Введение в PyTorch. Тензоры, автодифференцирование\n",
    "2. Feed-forward нейронные сети на Pytorch\n",
    "3. Dataloader, Dataset в Pytorch. Продвинутые методы оптимизации\n",
    "4. Сверточные сети в Pytorch. Классификация изображений. Предобученные сети в Pytorch\n",
    "5. Составная лосс-функция. Сегментация изображений.\n",
    "6. Сверточные сети применительно к текстовым задачам. Эмбеддинг-слои. Классификация новостей одномерными свертками.\n",
    "7. Рекурентные нейронные сети. GRU, LSTM на Pytorch. Задача NER.\n",
    "8. GAN на Pytorch.\n",
    "9. Bert и Transformer на Pytorch\n",
    "10. Face Detection and Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoFHbsJClrcw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch, вводное занятие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q9v2uVflrcw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### План занятия:\n",
    "\n",
    "* Установка\n",
    "* Тензоры\n",
    "* Введение в синтаксис pytorch и Тензорные вычисления\n",
    "* Вычислительный граф и Автоматическое диференцирование\n",
    "* Погружаемся в детали\n",
    "* Tensorflow vs PyTorch\n",
    "* Где полученные знания можно применить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsbYTszFlrcy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 0. Установка"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yxkIdBBrlrcz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3610af6a-2ca0-4286-975e-f515573096b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip3 install torch torchvision"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz-hpRAclrc4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioO3fIeclrc4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Тензоры схожи с ndarrays в NumPy, с добавлением того, что тензоры могут быть использованы на GPU для ускорения вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajgxH0z_AhhB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Тензоры\n",
    "\n",
    "Тензор - основная структура данных в библиотеках машинного обучения, которая похожа на массив Numpy. Что-то вроде n-мерной матрицы или массива массивов.Тензоры обеспечивают ускорение различных математических операций. Эти операции при выполнении в большом количестве в глубоком обучении имеют огромное значение в скорости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZzcooQUe83I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1pDiSoBIL8IBpIFq3R4OKGRW3YseBRvFm'>\n",
    "\n",
    "\n",
    "Визуализизация тензора с более чем двумя осями:\n",
    "\n",
    "<img src='https://drive.google.com/uc?Export=view&id=1C6pu0iDx1Ugz2OMyE9d6KZH9IcN3-STG'>\n",
    "<img src='https://drive.google.com/uc?export=view&id=1cmVLwGNLc8fkDpmNZreTecMNCXgD6zGl'>\n",
    "<img src='https://drive.google.com/uc?export=view&id=1XiGSZVsVQrlH279eu2IK1bekSvccX6aT'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Wwd8OUFlrc-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Введение в синтаксис pytorch и Тензорные вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo6pzUghlrc-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[База от pytorch](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cr4ur_8Llrc_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjBbSSOXlrdB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Тензоры в pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsP_QDjylrdC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Тип данных, хранимых тензором, отражается в имени его конструктора. Конструктор без параметров вернёт специальное значение — тензор без размерности, который нельзя использовать ни в каких операциях."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fZUu5E6klrdC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "torch.FloatTensor()\n",
    "a = torch.Tensor()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc2jfbOalrdD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Типы тензоров в pytorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRGslGDYlrdE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "torch.HalfTensor      # 16 бит, с плавающей точкой  \n",
    "torch.FloatTensor     # 32 бита,  с плавающей точкой  \n",
    "torch.DoubleTensor    # 64 бита, с плавающей точкой  \n",
    "\n",
    "torch.ShortTensor     # 16 бит, целочисленный, знаковый  \n",
    "torch.IntTensor       # 32 бита, целочисленный, знаковый  \n",
    "torch.LongTensor      # 64 бита, целочисленный, знаковый  \n",
    "\n",
    "torch.CharTensor      # 8 бит, целочисленный, знаковый  \n",
    "torch.ByteTensor      # 8 бит, целочисленный, беззнаковый  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3npMKfhHlrdF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "torch.Tensor является сокращённым названием для torch.FloatTensor. Так же в последних версиях существует автоматическое приведение типов, если типы не сопоставимы:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mP6jj5ImlrdF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a02e7414-1e60-418e-d201-a7bbd0fac077",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.FloatTensor([1.0])\n",
    "b = torch.DoubleTensor([2.0])\n",
    "print(a)\n",
    "print(b)\n",
    "a * b"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.])\n",
      "tensor([2.], dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2.], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULPsrNnxlrdH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Но где-то могут возникать проблемы в виду разных типов. Для этого предусмотрена возможность явного приведения типов:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mzydn0ntlrdI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e3817ef0-8f3c-4d1e-fc2d-be8112cf6260",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.IntTensor([1])\n",
    "print(a.type())\n",
    "a = a.byte()\n",
    "print(a.type())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.IntTensor\n",
      "torch.ByteTensor\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fDpxFj1mlrdJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "90a08fa6-ecea-4879-aaaf-99647a892dec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.float()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78WC03sMlrdK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Немного о различиях в функциях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hll1Lq_MlrdK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Соглашение о именовании в PyTorch гласит, что любая функция вида xxx возвращает новый тензор, т.е. является immutable функцией. В противоположность ей функция вида xxx_ изменяет изначальный тензор, т.е. является mutable функцией. Последние ещё носят название inplace функций. \n",
    "Почти для любой immutable функции в PyTorch существует её собрат. Однако бывает и так, что функция существует лишь в каком-то одном варианте. По понятным причинам, функции, изменяющие размер тензора всегда являются immutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5sdx0omlrdL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "По поводу всех функций прошу [сюда](https://pytorch.org/docs/master/tensors.html). А сейчас мы коснемся лишь самых важных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swyfZlVrlrdM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_XGiOlRlrdV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Начнем с того, как мы можем задать наш тензор. Полный список функций можно посмотреть в [официальном источнике](https://pytorch.org/docs/stable/torch.html) под заголовком Creation Ops. Вот некоторые разные варианты:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XBIvfmmzlrdW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "59e246f5-4f23-4d90-84c4-57f3fbd7c0f4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = [1. , 1.4 , 2.5]\n",
    "a_tensor = torch.tensor(a)\n",
    "print(f\"type of tensor : \", a_tensor.type())\n",
    "print(f\"Simple way: {torch.tensor(a)}\")\n",
    "print(f\"Via type : {torch.FloatTensor(a)}\")\n",
    "print(f\"Zeros:\\n {torch.zeros((2, 3))}\")\n",
    "print(f\"Превращаем а в нули : {a_tensor.zero_()}\")\n",
    "print(f\"Заполним тензор константой : {a_tensor.fill_(5)}\")\n",
    "print(f\"Range: {torch.arange(0, 10)}\")\n",
    "print(f\"Complicated range: {torch.arange(4, 12, 2)}\")\n",
    "print(f\"Space: {torch.linspace(1, 4, 6)}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type of tensor :  torch.FloatTensor\n",
      "Simple way: tensor([1.0000, 1.4000, 2.5000])\n",
      "Via type : tensor([1.0000, 1.4000, 2.5000])\n",
      "Zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Превращаем а в нули : tensor([0., 0., 0.])\n",
      "Заполним тензор константой : tensor([5., 5., 5.])\n",
      "Range: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Complicated range: tensor([ 4,  6,  8, 10])\n",
      "Space: tensor([1.0000, 1.6000, 2.2000, 2.8000, 3.4000, 4.0000])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIf4MP-ulrdX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4 Случайная выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rGBzeeKlrdX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь про то, как мы можем генерировать случайнные значения в наших тензорах. Полный список функций можно посмотреть по ссылке выше под заголовком Random sampling."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-vKQwM1olrdY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4894df6f-1d12-4bee-d05c-b3ea320d7a13",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"From 0 to 1: {torch.rand(1)}\")\n",
    "print(f\"Vector from 0 to 1: {torch.rand(5)}\")\n",
    "print(f\"Vector from a normal distribution with mean 0 and variance 1: {torch.randn(2, 3)}\")\n",
    "print(f\"Vector from 0 to 10: {torch.randint(10, size=(5,))}\")\n",
    "print(f\"Непрерывное равномерное распределение : {a_tensor.uniform_(0, 5)}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "From 0 to 1: tensor([0.8930])\n",
      "Vector from 0 to 1: tensor([0.6662, 0.7143, 0.8060, 0.3604, 0.1555])\n",
      "Vector from a normal distribution with mean 0 and variance 1: tensor([[-0.9367,  1.5774,  1.0464],\n",
      "        [ 0.6572,  0.6686,  0.0408]])\n",
      "Vector from 0 to 10: tensor([0, 6, 5, 6, 6])\n",
      "Непрерывное равномерное распределение : tensor([0.9304, 3.8502, 1.4885])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1apoSI34lrda",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.5 Математические операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eogPvK3olrdb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С матричными операциями так же все аналогично с тем же numpy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mMpVDkyOlrdb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5c0c56f5-7e98-4305-b09c-c505a25dc226",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "b = torch.linspace(-10, 10, 10)\n",
    "print(f\"a: {a}\\nshape: {a.size()}\")\n",
    "print(f\"b: {b}\\nshape: {b.size()}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "shape: torch.Size([10])\n",
      "b: tensor([-10.0000,  -7.7778,  -5.5556,  -3.3333,  -1.1111,   1.1111,   3.3333,\n",
      "          5.5556,   7.7778,  10.0000])\n",
      "shape: torch.Size([10])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wLvfZBI5niyi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2b5493ad-f16f-4a62-f443-48a8630c9d25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"a + b: {a + b},\\n a * b: {a * b}\")\n",
    "print(f\"a + b: {a.add(b)},\\n a * b: {a.mul(b)}\") # вычитание sub, деление - div\n",
    "print(f\"a + b: {a.add_(b)},\\n a * b: {a.mul_(b)}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([ -0.0000,  -7.7778, -11.1111, -10.0000,  -4.4444,   5.5556,  20.0000,\n",
      "         38.8889,  62.2222,  90.0000])\n",
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([ -0.0000,  -7.7778, -11.1111, -10.0000,  -4.4444,   5.5556,  20.0000,\n",
      "         38.8889,  62.2222,  90.0000])\n",
      "a + b: tensor([-10.0000,  -6.7778,  -3.5556,  -0.3333,   2.8889,   6.1111,   9.3333,\n",
      "         12.5556,  15.7778,  19.0000]),\n",
      " a * b: tensor([100.0000,  52.7160,  19.7531,   1.1111,  -3.2099,   6.7901,  31.1111,\n",
      "         69.7531, 122.7160, 190.0000])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w8ev2q3OnkSg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b9c7fb94-a255-4f91-ab35-450d2781254a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "\n",
    "print(f\"Экспонента : {a.exp()},\\n {torch.exp(a)}, \\n {a.exp_()}\")\n",
    "print(f\"Логарифм : {a.log()}\")\n",
    "print(f\"Модуль : {a.abs()}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Экспонента : tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]),\n",
      " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]), \n",
      " tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n",
      "Логарифм : tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Модуль : tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gqhs-wzFnlqm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1697c94-74c8-4b70-f35c-a6a7e58dba95",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Скалярное произведение: {a.dot(b)}\")\n",
    "print(f\"Mean: {a.mean()}, STD: {a.std()}\")\n",
    "print(f\"Sum: {a.sum()}, Min: {a.min()}, Max: {a.max()}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Скалярное произведение: 111618.328125\n",
      "Mean: 1281.830810546875, STD: 2571.337890625\n",
      "Sum: 12818.30859375, Min: 1.0, Max: 8103.083984375\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bqJzUTbESuO8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "530b9c10-6a6a-4538-a431-be2aa36c5d5d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b8FYpFBMnm9_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e1efefee-b302-49b8-b219-cb4439333c29",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Reshape:\\n{a.reshape(-1, 1)}\\nshape: {a.reshape(-1, 1).size()}\")\n",
    "c = a.reshape(-1, 1).repeat(1, 5)\n",
    "print(f\"Повторения:\\n{c}\\nshape: {c.size()}\")\n",
    "print(f\"Транспонирование:\\n{c.T}\\nshape: {c.T.size()}\")\n",
    "print(f\"Уникальные элементы: {torch.unique(c)}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reshape:\n",
      "tensor([[1.0000e+00],\n",
      "        [2.7183e+00],\n",
      "        [7.3891e+00],\n",
      "        [2.0086e+01],\n",
      "        [5.4598e+01],\n",
      "        [1.4841e+02],\n",
      "        [4.0343e+02],\n",
      "        [1.0966e+03],\n",
      "        [2.9810e+03],\n",
      "        [8.1031e+03]])\n",
      "shape: torch.Size([10, 1])\n",
      "Повторения:\n",
      "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.7183e+00, 2.7183e+00, 2.7183e+00, 2.7183e+00, 2.7183e+00],\n",
      "        [7.3891e+00, 7.3891e+00, 7.3891e+00, 7.3891e+00, 7.3891e+00],\n",
      "        [2.0086e+01, 2.0086e+01, 2.0086e+01, 2.0086e+01, 2.0086e+01],\n",
      "        [5.4598e+01, 5.4598e+01, 5.4598e+01, 5.4598e+01, 5.4598e+01],\n",
      "        [1.4841e+02, 1.4841e+02, 1.4841e+02, 1.4841e+02, 1.4841e+02],\n",
      "        [4.0343e+02, 4.0343e+02, 4.0343e+02, 4.0343e+02, 4.0343e+02],\n",
      "        [1.0966e+03, 1.0966e+03, 1.0966e+03, 1.0966e+03, 1.0966e+03],\n",
      "        [2.9810e+03, 2.9810e+03, 2.9810e+03, 2.9810e+03, 2.9810e+03],\n",
      "        [8.1031e+03, 8.1031e+03, 8.1031e+03, 8.1031e+03, 8.1031e+03]])\n",
      "shape: torch.Size([10, 5])\n",
      "Транспонирование:\n",
      "tensor([[1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03],\n",
      "        [1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "         4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03]])\n",
      "shape: torch.Size([5, 10])\n",
      "Уникальные элементы: tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrI9Y6-klrdd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.6 Индексирование"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gWKhVxkulrdd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "78b0ba8c-4d43-4f1b-da10-0e540e1edb18",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.arange(100).reshape(10, 10)\n",
    "print(f\"Array:\\n{a}\\nshape: {a.size()}\")\n",
    "print(f\"Get first column: {a[:, 0]}\")\n",
    "print(f\"Get last row: {a[-1, :]}\")\n",
    "print(f\"Add new aхis:\\n{a[:, np.newaxis]}\\nshape: {a[:, np.newaxis].size()}\")\n",
    "print(f\"Specific indexing:\\n{a[4:6, 7:]}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "shape: torch.Size([10, 10])\n",
      "Get first column: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Get last row: tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "Add new aхis:\n",
      "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]],\n",
      "\n",
      "        [[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n",
      "\n",
      "        [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]],\n",
      "\n",
      "        [[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]],\n",
      "\n",
      "        [[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]],\n",
      "\n",
      "        [[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]],\n",
      "\n",
      "        [[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]])\n",
      "shape: torch.Size([10, 1, 10])\n",
      "Specific indexing:\n",
      "tensor([[47, 48, 49],\n",
      "        [57, 58, 59]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxJ36RNblrde",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.7 Из numpy в pytorch и обратно"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Von-vTQxlrdk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b104c907-731d-45dc-f319-ffda946b361d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "a.numpy()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.68244714,  0.62198323,  0.25022632, -1.6830074 ],\n",
       "       [ 1.6847248 , -0.3822392 , -0.85305166, -0.96860546]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nQl1YKAVlrdl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7943a654-bb66-4101-b563-4c13088faeaa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "b = np.random.normal(size=(2, 4))\n",
    "torch.from_numpy(b)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.8420,  2.4610, -0.6426,  1.3732],\n",
       "        [ 1.2933, -0.2402, -1.5760, -0.6346]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB-V0qAFlrdm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.8 CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgH4-Qsklrdm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "torch.cuda - это пакет для поддержки CUDA. Он поддерживает такую же функциональность как и CPU, но использует CUDA ядра для вычислений. С полным функционалом можно ознакомиться [здесь](https://pytorch.org/docs/stable/cuda.html?highlight=cuda#module-torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cKi3yXWzlrdn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "86bcc4c5-df5d-47ac-b043-cc67dd6c1db1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(f\"Поддерживается ли CUDA : {torch.cuda.is_available()}\")\n",
    "print(f'Количество гпу девайсов: {torch.cuda.device_count()}')\n",
    "print(f\"Характеристики видеокарты : {torch.cuda.get_device_properties(0)}\")\n",
    "print(f\"Удаляем всю незанятую память через torch.cuda.empty_cache()\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Поддерживается ли CUDA : True\n",
      "Количество гпу девайсов: 1\n",
      "Характеристики видеокарты : _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n",
      "Удаляем всю незанятую память через torch.cuda.empty_cache()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYuP3-cHlrdo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Давайте посмотрим на практике как работать с cuda. Допустим мы инициализуем два тензора:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tDl0l9wQlrdo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ab9f37ad-664d-4c24-ca36-14c602ea1a4c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.normal(mean=torch.zeros(2, 4))\n",
    "b = torch.normal(mean=torch.zeros(2, 4))\n",
    "print(f\"a:\\n{a}\\nb:\\n{b}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a:\n",
      "tensor([[ 0.0589, -0.1010, -1.2611, -0.9362],\n",
      "        [-0.0176, -0.3726,  0.2276, -2.3432]])\n",
      "b:\n",
      "tensor([[-0.3900, -1.6025,  2.4657, -0.9067],\n",
      "        [-0.3015, -0.3575,  1.2346,  0.0938]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1K9I_VKlrdp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Наши тензоры автоматом загружены в память cpu. Но мы легко можем перевести их на cpu таким способом:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lDb6ruPvlrdq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "30a35e35-18e0-4de2-def8-486fdb3f11ac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = a.cuda()\n",
    "a"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0589, -0.1010, -1.2611, -0.9362],\n",
       "        [-0.0176, -0.3726,  0.2276, -2.3432]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha5DoFO5lrdq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь, если мы попробуем сложить эти два тензора, то у нас вылезет ошибка, т.к. один тензор на cpu, а другой на cuda:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UGwUNC2xlrdw",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "outputId": "9bbbfa01-c373-4b1c-b293-bb267e89ea02",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a + b"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-bd58363a63fc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0ma\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc627l3ulrdw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Мы не можем производить никакие операции с тензорами, находящимеся на разных устройствах. Что бы сложить их нам нужно оба тензора перевести на одно устройство:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xv7Vbf0glrdx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0dea90c7-cd3f-49ca-bb33-f50f64da37cf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a + b.cuda()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.1472, -0.7757,  3.6922,  2.1716],\n",
       "        [-0.6651,  1.1497, -0.3641,  0.3980]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X-WcdeyTlrdx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "132b5b55-2667-485c-f5cb-fc38fcf70a8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.cpu() + b"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.1472, -0.7757,  3.6922,  2.1716],\n",
       "        [-0.6651,  1.1497, -0.3641,  0.3980]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gmcJ4-dYlrdz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "da692905-eb93-48aa-9911-76c6f0dc8b9e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "(a + b.cuda()).cpu()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.1472, -0.7757,  3.6922,  2.1716],\n",
       "        [-0.6651,  1.1497, -0.3641,  0.3980]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBhzRlf5lrdz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Так же мы можем задать следующее определение устройства. Если  есть куда, то выбираем куду. В ином случае - цпу:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6_7usJoelrd0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b2b8e2e7-04b3-43a2-fdc5-2d37049b8cb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4RrmCBTlrd0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "У каждого тензора есть поле device, которое по умолчанию стоит cpu. Но мы можем менять его при инициализации или в процессе использования:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Tf4O-Jbzlrd7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d6922173-cfd0-43d7-8253-bbe4d9b02acb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "torch.randn(10, 10, device=device)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.4224, -1.1937,  0.0271, -0.2262, -0.6951,  0.3638, -1.0753,  1.1151,\n",
       "         -0.8861,  0.9608],\n",
       "        [ 0.6498, -0.7761, -1.1492, -0.1339, -0.4050,  0.6099,  1.3175,  0.2340,\n",
       "         -2.5075,  0.6270],\n",
       "        [ 1.6388,  1.6119, -0.4077,  0.6048,  0.8993,  0.8641, -1.4993,  1.7079,\n",
       "          0.9464,  0.0471],\n",
       "        [ 0.3054,  0.1716, -0.9051, -0.4246,  2.1928, -1.0221, -0.4439, -2.0037,\n",
       "          0.3975,  2.1976],\n",
       "        [ 0.3597,  1.7997,  0.0939,  1.5776, -0.5164,  0.3158, -0.5104, -0.9605,\n",
       "          0.3986, -0.7001],\n",
       "        [-0.9998,  2.4857, -0.6908, -1.3810, -0.0635, -0.4332,  0.1635, -0.7262,\n",
       "         -2.0225, -0.5887],\n",
       "        [-0.2252, -1.0018, -0.5191,  1.3870, -1.7483,  1.0340, -0.8379, -0.9106,\n",
       "         -0.9813,  0.0221],\n",
       "        [-0.2874, -0.6805, -1.6551,  2.0063,  2.4584,  0.6036,  0.2534, -0.2023,\n",
       "         -1.7951, -0.9322],\n",
       "        [-1.5458,  0.9506, -1.9442, -0.4270, -0.4487,  0.1997, -0.0877,  0.2874,\n",
       "         -0.3981,  0.5145],\n",
       "        [-0.8433, -1.1604, -1.3660,  1.0241,  1.4929,  1.7121,  2.1519,  1.1813,\n",
       "         -0.4024, -0.3386]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PQwfJX44lrd8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4150c343-e8db-48b1-a564-f4ca5e7e366d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.tensor((2 ,3))\n",
    "print(a)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtemnxcGlrd9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Переместить можно не только a.cuda(), но и так:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TrYYeQ2Ylrd9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c99d60f-996f-47f6-f741-14486485a89a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.to(device)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJfvB_s_lrd-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Но следует запомнить что .cuda() immutable функция. Т.е. она возвращает новый тензор, а не перезаписывает существующий a:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DHVkYlxWlrd-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3ac0181d-9e4e-4b17-9709-8bfcbae50ad9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r-u4QZ3lrd_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как видим наш тензор a все на том же cpu. Что бы интерпретатор запомнил что a у нас на куде необходимо присвоить значение выражение в тензор:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8PZP4VMqlrd_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = a.cuda()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jSnuqWi4lreA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "efee8e68-c879-4e8e-d40e-a922e3371130",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiV-LOESlreG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проверяем, находится ли сейчас тензор на куде:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6w2LyZpklreH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9298b185-3dd3-4f56-f673-67ecf6a83803",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.is_cuda"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Вычислительный граф и Автоматическое диференцирование\n"
   ],
   "metadata": {
    "id": "cN3pziw3r0kf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYIltf84lreJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### 3.1 Вычислительный граф\n",
    "\n",
    "Вычислительный граф — это иллюстрированная запись какой-либо функции, состоящая из вершин и рёбер. Вершины (или узлы) — вычислительные операции, которые необходимо выполнить, а рёбра связывают их в определённую последовательность.\n",
    "\n",
    "Автоматическое дифференцирование - строительный блок не только в Pytorch, но и в каждой другой DL библиотеке. Движок автоматического дифференцирования в Pytorch называет [Autograd](https://pytorch.org/docs/stable/autograd.html). \n",
    "\n",
    "Современные архитектуры нейронных сетей могут иметь миллионы обучающихся параметров. С вычислительной точки зрения тренировка сети состоит из двух фаз:\n",
    "\n",
    "1) Прямой проход для вычисления значения функции потерь.  \n",
    "2) Обратный проход для вычисления градиентов обучаемых параметров.\n",
    "\n",
    "Прямой проход весьма прямолинеен: выход одного слоя является входом другого.\n",
    "Обратный проход немного сложнее, поскольку он требует от нас использования цепного правила для вычисления градиентов весов относительно функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTUPg57vAhg6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ниже представлен простой пример вычислительного графа для вычисления выражения $\\sigma(x*w_1 + w_0)$. Можно разбить вычисление на следующие шаги:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DEEdtooAhg6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1jCTO6zBGyE8sYkkSv_6NENdFOiwuJCMC' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJMGxYF6Ahg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Преимущества использования вычислительного графа в том, что каждый узел является независимым функционирующим куском кода, если получит все необходимые входные данные. Это позволяет  оптимизировать производительность при выполнении расчетов, используя многоканальную обработку, параллельные вычисления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gbHTyn5lreo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 PyTorch Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZHQDshMlreo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь, когда мы понимаем, что такое вычислительный граф, вернемся к PyTorch и разберемся, как это реализовано в PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0415zzOllrep",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.1 Tензоры и requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUUpc9TGlrep",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как мы видели выше, тензор - это структура данных, которая является фундаментальным строительным блоком PyTorch и они во многом похожи на массивы numpy, за исключением того, что в отличие от numpy, тензоры предназначены для использования преимуществ параллельных вычислений графического процессора(GPU)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rnhj6vjolreq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6b253f3d-b47a-4523-f301-26f339a8bba3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch\n",
    "tsr = torch.Tensor(3,5)\n",
    "tsr"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[7.9394e+14, 0.0000e+00, 4.2039e-45, 0.0000e+00, 5.6052e-44],\n",
       "        [1.4013e-43, 1.4153e-43, 1.6535e-43, 1.4714e-43, 1.3873e-43],\n",
       "        [1.4153e-43, 5.7453e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAM31O5ylrer",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Вот он Tensor похожий на numpy ndarray. Структура данных, которая позволяет быстро выполнять операции линейной алгебры. Что бы сделать тензор обучающимся и мы бы смогли вычислить его градиент, необходимо поставить его параметр requires_grad в значение True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQX1h7uvlrer",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "requires_grad можно менять как при инициализации тензора, так и после:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NjB1sRIMlrex",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "80aeed1d-09e1-49b4-c3e6-b341f0eeaa29",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "t1 = torch.randn((3, 3), requires_grad=True)\n",
    "print(t1.requires_grad)\n",
    "t2 = torch.FloatTensor(3, 3)\n",
    "print(t2.requires_grad)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PJkO2Yuolrey",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "058ab413-391d-4047-87e4-28347c68320f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "t2.requires_grad = True\n",
    "print(t2.requires_grad)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzX5Atkmlrez",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "requires_grad заразителен. Это означает, что когда тензор создается с помощью других тензоров, для параметра requires_grad результирующего тензора будет установлено значение True, если хотя бы один из тензоров, используемых для создания, имеет для параметра requires_grad значение True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heK4cN4iq8Kp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*__Вопрос__: в каких ситуациях нам не нужен градиент для переменных?*\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lZ6G8eOqAhhU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "544412f0-40d5-4610-a71c-eeb40264d4d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = torch.ones(3, requires_grad=True)\n",
    "x"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_aXcleXAhhU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В x у нас хранится информация о градиенте. Мы можем получить ее через метод grad:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ft_gExlZAhhV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x.grad"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go7WnPwfAhhV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В данном случае ничего нет, т.к. мы никаких действий с нашим тензором не производили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G50J9jHEAhhV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Создадим переменную на основе x:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nIqgi87CAhhW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "z = (x ** 2) + 5.0 * x  # задание - посчитать производную руками"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cCl_FwTTAhhW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9cd1b7f4-ba12-4e83-cf88-ce08633f5a6f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "z"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6., 6., 6.], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwpCO-5hAhhW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Мы вызываем метод backward и передаем ей единичный тензор:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U2RngNdNAhhX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "z.backward(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMNtkwy6AhhX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "И тогда, когда мы выполнили эту функцию - мы вызываем градиент и мы получаем три 7ки:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DXcfyu2FAhhX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cc578154-07d5-4b3d-ea48-3a43c8e1435e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x.grad"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([7., 7., 7.])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8e4hHAybGqo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=1jCTO6zBGyE8sYkkSv_6NENdFOiwuJCMC' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFUmKCyCbGqx",
    "outputId": "07f50738-3a9c-4e41-f5b8-e20bc3cb3999",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = torch.FloatTensor([1])\n",
    "w1 = torch.tensor([0.417], requires_grad=True)\n",
    "w0 = torch.tensor([0.72], requires_grad=True)\n",
    "\n",
    "a = x * w1\n",
    "b = a + w0\n",
    "\n",
    "sigma = torch.nn.functional.sigmoid(b)\n",
    "mse = torch.nn.functional.mse_loss(sigma, x)\n",
    "mse"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0590, grad_fn=<MseLossBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Co67-_HqbGq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "mse.backward()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYWTMpiEbGq1",
    "outputId": "67172594-5d38-45fc-e741-36d98c997816",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "w1.grad, w0.grad"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([-0.0893]), tensor([-0.0893]))"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXn6KlzWlre0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "У каждого тензора есть атрибут grad_fn, который отсылается к функции (математическому оператору), создающему переменную. \n",
    "\n",
    "grad_fn будет равен None, если нет зависимых функций, к примеру, переменная `а`\n",
    "ни от чего не зависит, нет ни какой функции, из которой бы получилась переменная а, а значит и grad_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rGsqOfzQlre_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22502ae5-e0e3-4a24-cb19-345cb976efe2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a\n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c\n",
    "\n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is\", a.grad_fn)\n",
    "print(\"The grad fn for d is\", d.grad_fn)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The grad fn for a is None\n",
      "The grad fn for d is <AddBackward0 object at 0x7fd475e4f910>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhIb7fzAlrfA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Можно использовать функцию-член is_leaf, чтобы определить, является ли переменная листовым тензором или нет. Листовые тензоры - это тензоры, которые мы подаем в нашу систему вычислений. В нашем случае это а:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j5QIyVGOlrfB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d1e2e2c0-1679-4084-d069-c34c2c514753",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "a.is_leaf, w1.is_leaf"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RnZelZ9KlrfC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a7b89110-cb0c-4803-92fa-8249a9c43a1c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "L.is_leaf"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMm2QuehlrfD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.2 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSs52A0rlrfD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Все математические операции в PyTorch реализуются классом [torch.nn.Autograd.Function](https://pytorch.org/docs/stable/autograd.html#function). У этого класса есть две важные функции-члены, на которые нам нужно обратить внимание.\n",
    "\n",
    "Во-первых, это forward функция, которая просто вычисляет выходные данные, используя входные данные.\n",
    "\n",
    "Функция backward принимает входящий градиент, исходящий от части сети перед ней. Как вы можете видеть, градиент, который должен распространяться в обратном направлении от функции f, - это, по сути, градиент, который передается обратно в f от слоев перед ним, умноженный на локальный градиент выходных данных f по отношению к его входам. Именно это и делает обратная функция.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMXS85bmlrfG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Алгоритмически, вот как происходит обратное распространение с графом вычислений. (Не фактическая реализация, только пример):"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "\n",
    "def backward(incoming_gradients):\n",
    "    self.Tensor.grad = incoming_gradients\n",
    "\n",
    "    for inp in self.inputs:\n",
    "        if inp.grad_fn is not None:\n",
    "            new_incoming_gradients = incoming_gradient * local_grad(self.Tensor, inp)\n",
    "\n",
    "            inp.grad_fn.backward(new_incoming_gradients)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "MNm3GMI-lrfG",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EtJtoVblrfG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Здесь self.Tensor - это, тензор, созданный Autograd.Function, который использовался в нашем примере.\n",
    "\n",
    "Входящие градиенты и локальные градиенты были описаны выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLVqseSWlrfH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EJewzsLlrfJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Чтобы вычислить производные в нашей нейронной сети, мы обычно обращаемся к тензору, представляющему нашу потерю. Затем мы возвращаемся по графику, начиная с узла, представляющего grad_fn наших потерь.\n",
    "\n",
    "Как описано выше, обратная функция рекурсивно вызывается по графику, когда мы возвращаемся. Однажды мы достигаем листового узла, поскольку grad_fn равен None, но прекращаем возвращение по этому пути.\n",
    "\n",
    "Здесь следует отметить, что PyTorch выдает ошибку, если вы вызываете backward () для векторного тензора. Это означает, что вы можете выполнять обратный вызов только для тензорного скалярного значения. В нашем примере, если мы предположим, что a - тензор с векторным значением, и обратимся к L, он выдаст ошибку."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OHnXE1tDlrfJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "outputId": "5af46f45-4036-458f-ceae-771519dcccd9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a \n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c \n",
    "\n",
    "L = (10 - d)\n",
    "print(L)\n",
    "\n",
    "L.backward()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[10.4130, 10.0158, 10.3634],\n",
      "        [ 9.4820, 10.0306,  9.6519],\n",
      "        [ 8.7853, 10.5513, 10.1320]], grad_fn=<RsubBackward1>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-50-04b6b2e5b3ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    361\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    362\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 363\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    365\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[0mgrad_tensors_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_tensor_or_tensors_to_tuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 166\u001B[0;31m     \u001B[0mgrad_tensors_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_grads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_grads_batched\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    167\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mretain_graph\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36m_make_grads\u001B[0;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequires_grad\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"grad can be implicitly created only for scalar outputs\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m                 \u001B[0mnew_grads\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mones_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreserve_format\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd_gEROTlrfK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Это потому, что градиенты могут быть вычислены относительно скалярных значений по определению. Вы не можете точно отличить вектор от другого вектора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETgNADiolrfL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если вы просто сделаете небольшое изменение в приведенном выше коде, установив L как сумму всех ошибок, наша проблема будет решена."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SUdyzF2WlrfL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af9df7fb-967d-4aab-98be-6b7e5ab44e6b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch \n",
    "\n",
    "a = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad=True)\n",
    "w2 = torch.randn((3,3), requires_grad=True)\n",
    "w3 = torch.randn((3,3), requires_grad=True)\n",
    "w4 = torch.randn((3,3), requires_grad=True)\n",
    "\n",
    "b = w1 * a \n",
    "c = w2 * a\n",
    "\n",
    "d = w3 * b + w4 * c \n",
    "\n",
    "# Replace L = (10 - d) by \n",
    "L = (10 - d).sum()\n",
    "print(L)\n",
    "\n",
    "L.backward()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(98.3699, grad_fn=<SumBackward0>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUVG6dtolrfN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как только это будет сделано, вы можете получить доступ к градиентам, вызвав атрибут grad в Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geQBtfx6lrfQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.3 Некоторые хитрости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPyuy1PxlrfR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1) requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-adpm4BrlrfR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Это атрибут класса Tensor. По умолчанию это False. Это удобно, когда вам нужно заморозить некоторые слои и запретить им обновлять параметры во время тренировки. Вы можете просто установить для параметра requires_grad значение False, и эти тензоры не будут участвовать в графе вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE87s9HhlrfS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2) torch.no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOHxTUA-lrfh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Когда мы вычисляем градиенты, нам нужно кэшировать входные значения и промежуточные функции, поскольку они могут потребоваться для вычисления градиента позже.  Если нам нужно сохранить эти значения для вычисления градиента во время обратного прохода, это повлияет на объем памяти, занимаемой сетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ2CMPD3lrfi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "С использованием torch.no_grad мы выполняем вывод нашей нейронной сети и мы не вычисляем градиенты и, следовательно, нам не нужно хранить эти значения. Фактически, во время вывода графа вычислений создавать не нужно, так как это приведет к бесполезному потреблению памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjayYcWxlrfj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "PyTorch предлагает для этой цели диспетчер контекста, называемый torch.no_grad."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F5IRJk1Wlrfj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "    # inference code goes here \n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MMq6SyGlrfk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Погружаемся в детали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkcMK9v7lrfl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Все основные модули которые будут рассматриваться ниже находятся в [torch.nn](https://pytorch.org/docs/stable/nn.html#). Все кроме оптимизаторов - они находятся в [torch.optim](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuo6jRyclrfl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1. Слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqyiBsZslrfm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Линейный слой (Линейное преобразование)\n",
    "\n",
    "[pytorch doc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "\n",
    "$$y = xA^T + b$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wW0hJOqRlrfr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "layer = torch.nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=2,\n",
    "    bias=True\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBymHmwoO6Gc",
    "outputId": "7e59af81-df22-461b-9bd0-18348c5bca14",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "layer.weight, layer.bias"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.4247, 0.2085, 0.0874],\n",
       "         [0.1928, 0.0269, 0.3377]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.5558, -0.2596], requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHImPO4olrgZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2 Алгоритм обучения в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "phZxJlZ5lrgZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leaG6UYdlrgb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Для начала нам нужна модель через которую мы будем прогонять данные и получать какой-то результат. Для этого возьмем линейное преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8p_Y5Ix8lrge",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "linear = nn.Linear(2, 2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCYlfLIZlrgf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "У слоя в pytorch мы всегда можем посмотреть веса и отклонение:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QfmjSh0wlrgg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "abff38d5-1a2f-4cc8-aa80-c6d78e87d575",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print('w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.3702, -0.4406],\n",
      "        [ 0.0354, -0.3520]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.1948, 0.0449], requires_grad=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcEQk9xklrgg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Теперь нам нужно определить функцию ошибок для подсчета градиента:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ktjXPigolrgh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "criterion = nn.MSELoss()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s5fLcGGlrgm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Так же нам нужен оптимизатор который будет изменять веса нашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQoaffbOlrgm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsft9Mrulrgn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Нам нужны данные (х) и верные метки (y) по которым мы поймем правильные ли предсказания делает модель. (В данном случае у нас всего пара значений (данные, метки). О том как организовывать много данных ниже и в дальнейших вебинарах):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0aXEA3OGlrgn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b7c3b54-723a-4ab5-ac53-75b7fdaa6864",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = torch.randn(2, requires_grad=True)\n",
    "y = torch.randn(2, requires_grad=False)\n",
    "\n",
    "x, y"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([-1.1085,  0.8135], requires_grad=True), tensor([-0.2323,  0.2888]))"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT-kKVE7lrgo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Перед тем как считать градиенты и менять веса, нам нужно обнулить градиенты хранящиеся в свойстве тензора .grad. Для этого выполняем следующую строчку кода:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JdByvAdylrgo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "optimizer.zero_grad()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nleewGB2lrgp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Затем делаем предсказание на наших данных х, получаем предсказание модели и сохраняем это предсказание в переменную pred:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6vd31Yqxlrgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "pred = linear(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_xyEM2Ilrgq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. Переменная pred имеет ту же размерность, что и y. y - это наша правильная метка (ground truth). На этом этапе мы сравниваем предсказанное с реальным и получаем некую численную оценку этого через функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KMATmsD0lrgq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3132502c-075a-4814-b214-7db79b0cb4b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss, ' \\nloss_item :', loss.item())"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  tensor(0.2769, grad_fn=<MseLossBackward0>)  \n",
      "loss_item : 0.2769017815589905\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LBFt80flrgr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Стоит отметить, что если мы посмотрим на переменную .grad наших весов и отклонения, то ничего не будет:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CUIp6jQtlrgs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "13b24dff-e972-479e-aba8-9b4acadf67f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print('dL/dw: ', linear.weight.grad) \n",
    "print('dL/db: ', linear.bias.grad)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dL/dw:  None\n",
      "dL/db:  None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpKSxAbulrgs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Это потому что мы не начинали идти в обратном направлении и высчитывать градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyCJdzdclrgt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "8. Что ж, самое время это сделать. Проходим в обратном направлении и вычислим градиенты:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JroDNpxJlrgt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "loss.backward()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlzi3IZflrgu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь если мы посмотрим на grad весов, то уже что-то увидим:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S2jqTzv5lrgu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "69f0137e-4ad4-44cb-84f4-22551ac54320",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print('w: ', linear.weight.grad)\n",
    "print('b: ', linear.bias.grad)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w:  tensor([[-0.5310,  0.3897],\n",
      "        [ 0.6313, -0.4633]])\n",
      "b:  tensor([ 0.4790, -0.5695])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96uo8Dyulrgv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "9. Теперь самое время поменять веса. Для этого надо сделать так называемый шаг оптимизатора. Здесь оптимизатор имея информацию о высчитанных градиентах и значениях весов меняет последние:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JOQ1VXTOlrgv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6326f4b4-7c50-47a4-e38a-7a675317511b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Веса до\n",
    "print('BEFORE:\\n','w: ', linear.weight)\n",
    "print('b: ', linear.bias, '\\n')\n",
    "\n",
    "# Делаем шаг оптимизатора\n",
    "optimizer.step()\n",
    "\n",
    "# Веса после\n",
    "print('AFTER:\\n''w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BEFORE:\n",
      " w:  Parameter containing:\n",
      "tensor([[-0.3702, -0.4406],\n",
      "        [ 0.0354, -0.3520]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.1948, 0.0449], requires_grad=True) \n",
      "\n",
      "AFTER:\n",
      "w:  Parameter containing:\n",
      "tensor([[-0.3649, -0.4445],\n",
      "        [ 0.0291, -0.3474]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.1901, 0.0506], requires_grad=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HhgLc7nlrhR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  5. Tensorflow vs PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZvXLj-RlrhS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src='https://drive.google.com/uc?export=view&id=13SNw7d9JGT8lHMrKN2-mNgYrqKqkNXfG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjwlR38ylrhT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Определение графа - верно для старых версий, в Октябре 2019 года добавили поддержку подобного стиля программирования "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2zYPfsDlrhV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Различия:\n",
    "\n",
    "PyTorch разработал Facebook Lab в 2016 году, здесь динамическое определение графа. А Tensorflow разрабатывался командой Google Brains в 2015 и до 2019 года граф определялся только статически.\n",
    "\n",
    "В TensorFlow граф определяется статически перед запуском модели. Связь осуществляется с помощью объекта tf.Session и tf.Placeholder — тензорами, которые во время выполнения программы будут заменены внешними данными.\n",
    "\n",
    "В PyTorch можно определять, изменять и выполнять узлы как вам угодно без дополнительных session- и placeholder-интерфейсов. Когда вы пишите на TensorFlow, иногда кажется, что с моделью можно связываться через несколько крошечных отверстий в кирпичной стене, за которой и прячется модель.\n",
    "\n",
    "Существуют архитектуры нейронных сетей, которые получают преимущества от динамического подхода. RNN со статическим графом длина входной последовательности остается постоянной. Это означает, что необходимо зафиксировать длину предложения на максимальном значении, а все более мелкие последовательности заполнять нулями.\n",
    "\n",
    "Но теперь и в Tensorflow и PyTorch есть возможность динамического определения графа.\n",
    "\n",
    "\n",
    "<img src='https://drive.google.com/uc?export=view&id=1YceAfoUFkzUo_nHPwpwW8OuklFlQGMwu'>\n",
    "\n",
    "[Ссылка](https://chel-center.ru/python-yfc/2020/12/22/pytorch-protiv-tensorflow-dlya-vashego-proekta-glubokogo-obucheniya-python/) на статью где хорошо объясняется различие pytorch от tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3btv8V0QlrhW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Где полученные знания можно применять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDMm1C17lrhX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "pytorch можно использовать в следующих областях:\n",
    "* Распознавание и синтез аудио. Об этом [torchaudio](https://pytorch.org/audio/stable/index.html)  \n",
    "* Так же с инструментом pytorch можно заниматься регрессионными проблемами, прогнозирования временных рядов. Например предсказывать цены на определенные валюты, акции, дома и т.д. [ссылка](https://www.machinelearningmastery.ru/lstm-for-time-series-prediction-de8aeb26f2ca/)\n",
    "* [Задачи NLP](https://pytorchnlp.readthedocs.io/en/latest/index.html#)  \n",
    "* Можно генерировать разную информацию от картинок до текста и аудио.\n",
    "\n",
    "В общем pytorch можно применять везде, где используются нейронные сети.\n",
    "\n",
    "[Бонус](https://www.8host.com/blog/kak-ustanovit-i-ispolzovat-pytorch/): зайдите по ссылке и долистайте до \"Экосистема Pytorch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkJ7emsMxaYF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Ноутбук: https://colab.research.google.com/drive/1l_ngLK9Ltwkd8Gkv9WwQYGo_ctCs3HvY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfRSfecExTgi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Дополнительные материалы\n",
    "1. [Pytorch vs Tensorflow in 2020](https://towardsdatascience.com/pytorch-vs-tensorflow-in-2020-fe237862fae1)\n",
    "2. [Официальная документация PyTorch](https://pytorch.org/tutorials/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4TESt3AxXg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Определения\n",
    "\n",
    "\n",
    "**Вычислительный граф** — это иллюстрированная запись какой-либо функции, состоящая из вершин и рёбер. Вершины (или узлы) — вычислительные операции, которые необходимо выполнить, а рёбра связывают их в определённую последовательность.\n",
    "\n",
    "Шаги обучения:\n",
    "1. Проход по батчу\n",
    "2. Обнуление градиента\n",
    "3. Предсказание модели на батче\n",
    "4. Подсчет ошибки\n",
    "5. Подсчет градиентов\n",
    "6. Шаг оптимизации\n",
    "7. Логирование информации"
   ]
  }
 ]
}